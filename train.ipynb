{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras_tuner import (\n",
    "    Hyperband,\n",
    "    HyperParameters,\n",
    ")\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from tensorflow.data import (\n",
    "    AUTOTUNE,\n",
    "    Dataset,\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import (\n",
    "    Model,\n",
    "    regularizers,\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPool2D,\n",
    "    MaxPooling2D,\n",
    "    RandomFlip,\n",
    "    RandomRotation,\n",
    "    RandomZoom,\n",
    "    Rescaling,\n",
    ")\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.models import (\n",
    "    clone_model,\n",
    "    Sequential,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    List,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "from src import (\n",
    "    Dataset as WSI_Dataset,\n",
    "    ModelContext,\n",
    "    ModelFactory,\n",
    ")\n",
    "\n",
    "import itertools\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "IMG_WIDTH = 200\n",
    "IMG_HEIGHT = 200\n",
    "\n",
    "\n",
    "# The name of the model to be trained, should not include the file extension\n",
    "# None if a new model is to be trained\n",
    "OVERWRITE_MODEL: Optional[str] = None\n",
    "\n",
    "\n",
    "# Set to True if data augmentation is to be used\n",
    "DATA_AUGMENTATION: bool = False\n",
    "# The `DATA_AUGMENTATION_LAYERS` will be used only if `DATA_AUGMENTATION` is True\n",
    "DATA_AUGMENTATION_LAYERS = [\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "# Variables for the model\n",
    "BATCH_SIZE: int = 4\n",
    "VALIDATION_SPLIT: float = 0.3\n",
    "\n",
    "\n",
    "# The number of neurons in the final layer, should be 12 for this dataset\n",
    "FINAL_LAYER_UNITS: int = 12\n",
    "\n",
    "\n",
    "def HYPERMODEL_CREATION_CALLBACK(\n",
    "    hp: HyperParameters,\n",
    "    *,\n",
    "    model: Optional[Model]=None,\n",
    ") -> Model:\n",
    "    \"\"\"The function to create a hypermodel\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Rescaling(1. / 255),\n",
    "                Conv2D(\n",
    "                    filters=hp.Int(\"conv_1_filter\", min_value=32, max_value=128, step=16),\n",
    "                    kernel_size=hp.Choice(\"conv_1_kernel\", values=[3, 5]),\n",
    "                    kernel_regularizer=regularizers.l2(hp.Choice(\"conv_1_l2\", values=[1e-3, 1e-4, 1e-5, 1e-6])),\n",
    "                    activation=\"relu\",\n",
    "                    input_shape=(None, IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "                ),\n",
    "                MaxPooling2D(\n",
    "                ),\n",
    "                Dropout(\n",
    "                    rate=hp.Float(\"dropout_1_rate\", min_value=0.1, max_value=0.8, step=0.1),\n",
    "                ),\n",
    "                Conv2D(\n",
    "                    filters=hp.Int(\"conv_2_filter\", min_value=32, max_value=128, step=16),\n",
    "                    kernel_regularizer=regularizers.l2(hp.Choice(\"conv_2_l2\", values=[1e-3, 1e-4, 1e-5, 1e-6])),\n",
    "                    kernel_size=hp.Choice(\"conv_2_kernel\", values=[3, 5]),\n",
    "                    activation=\"relu\",\n",
    "                ),\n",
    "                MaxPooling2D(\n",
    "                ),\n",
    "                Dropout(\n",
    "                    rate=hp.Float(\"dropout_2_rate\", min_value=0.1, max_value=0.8, step=0.1),\n",
    "                ),\n",
    "                Flatten(\n",
    "                    input_shape=(None, IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "                ),\n",
    "                Dense(\n",
    "                    units=hp.Int(\"dense_1_units\", min_value=32, max_value=512, step=32),\n",
    "                    kernel_regularizer=regularizers.l2(hp.Choice(\"dense_1_l2\", values=[1e-3, 1e-4, 1e-5, 1e-6])),\n",
    "                    activation=\"relu\",\n",
    "                ),\n",
    "                Dropout(\n",
    "                    rate=hp.Float(\"dropout_3_rate\", min_value=0.1, max_value=0.5, step=0.1),\n",
    "                ),\n",
    "                Dense(\n",
    "                    units=FINAL_LAYER_UNITS,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss=SparseCategoricalCrossentropy(\n",
    "            from_logits=True\n",
    "        ),\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def FIT_CALLBACKS(model_name: str) -> List[Callable]:\n",
    "    \"\"\"The callbacks to be called after done of each epoch\n",
    "    \"\"\"\n",
    "    return [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=15,\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f\"caches/checkpoints/{model_name}.keras\",\n",
    "            monitor=\"val_accuracy\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        TensorBoard(\n",
    "            log_dir=f\"logs/fit/{model_name}\",\n",
    "            histogram_freq=1,\n",
    "            profile_batch=0,\n",
    "        ),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "_raw_train_ds, _raw_val_ds, _raw_test_ds = WSI_Dataset.get(validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "class_names = _raw_train_ds.class_names\n",
    "\n",
    "logger.info(f\"Raw train set with {len(_raw_train_ds)} samples and {len(_raw_train_ds.class_names)} of classes, which are {', '.join(_raw_train_ds.class_names)}\")\n",
    "logger.info(f\"Raw validation set with {len(_raw_val_ds)} samples and {len(_raw_val_ds.class_names)} of classes, which are {', '.join(_raw_val_ds.class_names)}\")\n",
    "logger.info(f\"Raw test set with {len(_raw_test_ds)} samples and {len(_raw_test_ds.class_names)} of classes, which are {', '.join(_raw_test_ds.class_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def _process_ds(ds: Dataset, batch: int, shuffle: bool) -> Dataset:\n",
    "    ds = ds.batch(batch)\n",
    "\n",
    "    if shuffle:\n",
    "        ds.shuffle(buffer_size=500, reshuffle_each_iteration=True)\n",
    "\n",
    "    ds = ds.cache()\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def _augment(ds: Dataset) -> Dataset:\n",
    "    data_augmentation = Sequential(DATA_AUGMENTATION_LAYERS)\n",
    "\n",
    "    result = ds.map(\n",
    "        lambda x, y: (data_augmentation(x, training=True), y),\n",
    "        num_parallel_calls=AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "    _raw_train_ds = _augment(_raw_train_ds)\n",
    "    _raw_val_ds = _augment(_raw_val_ds)\n",
    "    logger.info(\"Dataset has been augmented\")\n",
    "\n",
    "\n",
    "train_ds = _process_ds(_raw_train_ds, batch=BATCH_SIZE, shuffle=True)\n",
    "val_ds = _process_ds(_raw_val_ds, batch=BATCH_SIZE, shuffle=False)\n",
    "test_ds = _process_ds(_raw_test_ds, batch=1, shuffle=False)\n",
    "\n",
    "logger.info(f\"Batched train set with {len(train_ds)} samples\")\n",
    "logger.info(f\"Batched validation set with {len(val_ds)} samples\")\n",
    "logger.info(f\"Test set with {len(test_ds)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the first image of each labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "_taken_classes = set()\n",
    "\n",
    "_images_list = []\n",
    "_labels_list = []\n",
    "\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for i in range(images.shape[0]):\n",
    "\n",
    "        if labels[i].numpy() in _taken_classes:\n",
    "            continue\n",
    "\n",
    "        _taken_classes.add(labels[i].numpy())\n",
    "\n",
    "        _images_list.append(images[i])\n",
    "        _labels_list.append(labels[i])\n",
    "\n",
    "        if len(_taken_classes) >= len(class_names):\n",
    "            break\n",
    "\n",
    "    if len(_taken_classes) >= len(class_names):\n",
    "        break\n",
    "\n",
    "\n",
    "_images_tensor = tf.stack(_images_list)\n",
    "_labels_tensor = tf.stack(_labels_list)\n",
    "\n",
    "logger.debug(f\"Images tensor shape: {_images_tensor.shape}\")\n",
    "logger.debug(f\"Labels tensor shape: {_labels_tensor.shape}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "for image, label in zip(_images_tensor, _labels_tensor):\n",
    "    plt.subplot(3, 4, label.numpy() + 1)\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if OVERWRITE_MODEL is not None:\n",
    "    _contexts: List[ModelContext] = ModelContext.models()\n",
    "    context: Optional[ModelContext] = next(\n",
    "        filter(lambda x: x.name == OVERWRITE_MODEL, _contexts),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if context is None:\n",
    "        raise ValueError(f\"Model {OVERWRITE_MODEL} not found\")\n",
    "\n",
    "    logger.info(f\"Model {context.name} will be used for this training\")\n",
    "\n",
    "\n",
    "else:\n",
    "    context = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit\n",
    "\n",
    "\n",
    "initial_model: Optional[Model] = clone_model(context.model) if context is not None else None\n",
    "\n",
    "\n",
    "tuner = Hyperband(\n",
    "    lambda hp: HYPERMODEL_CREATION_CALLBACK(\n",
    "        hp,\n",
    "        model=initial_model,\n",
    "    ),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    directory=\"caches\",\n",
    "    project_name=\"hyperband\",\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search(\n",
    "    train_ds,\n",
    "    epochs=200,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=FIT_CALLBACKS(\"hyperband\"),\n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "logger.debug(f\"Best HPs: {best_hps}\")\n",
    "logger.success(\n",
    "    f\"The hyperparameter search is complete. The optimal values are\\n\" + \\\n",
    "    \"\\n\".join([f\"{k.capitalize():25s}: {v}\" for k, v in best_hps.values.items()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "__model: Model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "\n",
    "if context is not None:\n",
    "    context.model = __model\n",
    "    logger.info(f\"Re-using the model {context.name}\")\n",
    "\n",
    "else:\n",
    "    context = ModelFactory.create(__model)\n",
    "    logger.info(f\"Created a new model {context.name}\")\n",
    "\n",
    "\n",
    "context.model.summary(\n",
    "    expand_nested=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "history = context.model.fit(\n",
    "    train_ds,\n",
    "    callbacks=FIT_CALLBACKS(context.name),\n",
    "    validation_data=val_ds,\n",
    "    epochs=10000,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_result = context.model.evaluate(test_ds)\n",
    "logger.info(f\"Test loss: {eval_result[0]}\")\n",
    "logger.info(f\"Test accuracy: {eval_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "best_epoch = history.history[\"val_accuracy\"].index(\n",
    "    max(history.history[\"val_accuracy\"])\n",
    ") + 1\n",
    "\n",
    "\n",
    "logger.debug(f\"Best epoch: {best_epoch}\")\n",
    "logger.info(f\"Re-instantiate the hypermodel and train it with the optimal number of epochs {best_epoch}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "context.model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "context.model.fit(\n",
    "    train_ds,\n",
    "    callbacks=FIT_CALLBACKS(context.name),\n",
    "    validation_data=val_ds,\n",
    "    epochs=best_epoch,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "eval_result = context.model.evaluate(test_ds)\n",
    "logger.info(f\"Test loss: {eval_result[0]}\")\n",
    "logger.info(f\"Test accuracy: {eval_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "predictions = context.model.predict(\n",
    "    test_ds,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "logger.debug(f\"Predictions shape: {predictions.shape}\")\n",
    "logger.debug(f\"Predictions\\n{predictions}\")\n",
    "\n",
    "\n",
    "actual = np.array([l.numpy() for _, l in test_ds])\n",
    "predicted = np.argmax(predictions, axis=-1)\n",
    "\n",
    "logger.debug(f\"Actual shape: {actual.shape}\")\n",
    "logger.debug(f\"Actual values\\n{actual}\")\n",
    "\n",
    "logger.debug(f\"Predicted shape: {predicted.shape}\")\n",
    "logger.debug(f\"Predicted values\\n{predicted}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "\n",
    "logger.debug(f\"Confusion Matrix\\n{cm}\")\n",
    "\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=class_names,\n",
    ")\n",
    "\n",
    "cm_display.plot(\n",
    "    cmap=\"Blues\",\n",
    "    ax=plt.subplots(figsize=(9, 9))[1]\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "logger.info(f\"Accuracy: {accuracy_score(actual, predicted)}\")\n",
    "logger.info(f\"Precision: {precision_score(actual, predicted, average='micro')}\")\n",
    "logger.info(f\"Sensitivity recall: {recall_score(actual, predicted, average='micro')}\")\n",
    "logger.info(f\"Specificity: {recall_score(actual, predicted, pos_label=0, average='micro')}\")\n",
    "logger.info(f\"F1 score: {f1_score(actual, predicted, average='micro')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "context.model.summary()\n",
    "context.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wood-species-identification-hpklw3A5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
